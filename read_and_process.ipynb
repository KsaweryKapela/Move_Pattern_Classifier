{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "data_path = os.getenv('RAW_DATA_PATH')\n",
    "\n",
    "categories = {'idle': 'idle',\n",
    "              'running': 'run',\n",
    "              'stairs': 'stair',\n",
    "              'walking': 'walk'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def get_col_names():\n",
    "    col_names = []\n",
    "\n",
    "    for i in range(1, 31):\n",
    "        for l in ['x', 'y', 'z']:\n",
    "            col_names.append(f'{l}_{i}')\n",
    "            \n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for category, label in categories.items():\n",
    "    category_path = os.path.join(data_path, category)\n",
    "    \n",
    "    for sample_num, file in enumerate(sorted(os.listdir(category_path), key=natural_sort_key)):\n",
    "        \n",
    "        file_path = os.path.join(category_path, file)\n",
    "        raw_df = pd.read_csv(file_path)\n",
    "        temp_df = pd.DataFrame([raw_df.values.flatten()], columns=get_col_names())\n",
    "        temp_df['action'] = label\n",
    "        \n",
    "        dataframes.append(temp_df)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, skew, kurtosis\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mean(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].mean(axis=1)\n",
    "\n",
    "def calculate_variance(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].var(axis=1)\n",
    "\n",
    "def calculate_std_dev(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].std(axis=1)\n",
    "\n",
    "def calculate_median(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].median(axis=1)\n",
    "\n",
    "def calculate_range(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].max(axis=1) - df[[f'{sensor}_{i}' for i in range(1, 31)]].min(axis=1)\n",
    "\n",
    "def calculate_max_value(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].max(axis=1)\n",
    "\n",
    "def calculate_min_value(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].min(axis=1)\n",
    "\n",
    "def calculate_rms(df, sensor):\n",
    "    return np.sqrt((df[[f'{sensor}_{i}' for i in range(1, 31)]] ** 2).mean(axis=1))\n",
    "\n",
    "def calculate_signal_magnitude_area(df, sensor):\n",
    "    return np.abs(df[[f'{sensor}_{i}' for i in range(1, 31)]]).sum(axis=1)\n",
    "    \n",
    "def calculate_index_of_max_value(df, sensor):\n",
    "    max_value_indices = df[[f'{sensor}_{i}' for i in range(1, 31)]].idxmax(axis=1)\n",
    "    return max_value_indices.apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "def calculate_index_of_min_value(df, sensor):\n",
    "    min_value_indices = df[[f'{sensor}_{i}' for i in range(1, 31)]].idxmin(axis=1)\n",
    "    return min_value_indices.apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "def calculate_power(df, sensor):\n",
    "    return (df[[f'{sensor}_{i}' for i in range(1, 31)]] ** 2).mean(axis=1)\n",
    "\n",
    "def calculate_energy(df, sensor):\n",
    "    return (df[[f'{sensor}_{i}' for i in range(1, 31)]] ** 2).sum(axis=1)\n",
    "\n",
    "def calculate_entropy(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].apply(lambda x: entropy(x + np.abs(x.min()) + 1), axis=1)\n",
    "\n",
    "def calculate_skewness(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].skew(axis=1)\n",
    "\n",
    "def calculate_kurtosis(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].apply(kurtosis, axis=1)\n",
    "\n",
    "def calculate_interquartile_range(df, sensor):\n",
    "    return df[[f'{sensor}_{i}' for i in range(1, 31)]].quantile(0.75, axis=1) - df[[f'{sensor}_{i}' for i in range(1, 31)]].quantile(0.25, axis=1)\n",
    "\n",
    "def calculate_mean_absolute_deviation(df, sensor):\n",
    "    sensor_columns = [f'{sensor}_{i}' for i in range(1, 31)]\n",
    "    mean_values = df[sensor_columns].mean(axis=1)\n",
    "    return df[sensor_columns].subtract(mean_values, axis=0).abs().mean(axis=1)\n",
    "\n",
    "for l in ['x', 'y', 'z']:\n",
    "    df[f'{l}_mean'] = calculate_mean(df, l)\n",
    "    df[f'{l}_variance'] = calculate_variance(df, l)\n",
    "    df[f'{l}_std'] = calculate_std_dev(df, l)\n",
    "    df[f'{l}_median'] = calculate_median(df, l)\n",
    "    df[f'{l}_range'] = calculate_range(df, l)\n",
    "    df[f'{l}_max_value'] = calculate_max_value(df, l)\n",
    "    df[f'{l}_min_value'] = calculate_min_value(df, l)\n",
    "    df[f'{l}_rms'] = calculate_rms(df, l)\n",
    "    df[f'{l}_signal_magnitude_area'] = calculate_signal_magnitude_area(df, l)\n",
    "    df[f'{l}_index_max_value'] = calculate_index_of_max_value(df, l)\n",
    "    df[f'{l}_index_min_value'] = calculate_index_of_min_value(df, l)\n",
    "    df[f'{l}_power'] = calculate_power(df, l)\n",
    "    df[f'{l}_energy'] = calculate_energy(df, l)\n",
    "    df[f'{l}_entropy'] = calculate_entropy(df, l)\n",
    "    df[f'{l}_skewness'] = calculate_skewness(df, l)\n",
    "    df[f'{l}_kurtosis'] = calculate_kurtosis(df, l)\n",
    "    df[f'{l}_interquartile_range'] = calculate_interquartile_range(df, l)\n",
    "    df[f'{l}_mean_absolute_deviation'] = calculate_mean_absolute_deviation(df, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_cross_correlation(row, sensor1, sensor2):\n",
    "    sensor1_values = row[[f'{sensor1}_{i}' for i in range(1, 31)]].values\n",
    "    sensor2_values = row[[f'{sensor2}_{i}' for i in range(1, 31)]].values\n",
    "    return pd.Series(sensor1_values).corr(pd.Series(sensor2_values))\n",
    "\n",
    "for pair in [('x', 'y'), ('y', 'z'), ('z', 'x')]:\n",
    "    sensor1, sensor2 = pair\n",
    "    df[f'cross_corr_{sensor1}_{sensor2}'] = df.apply(lambda row: calculate_row_cross_correlation(row, sensor1, sensor2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = pd.factorize(df['action'])[0]\n",
    "df.to_csv('complete_ds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_player",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
